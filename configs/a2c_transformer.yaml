input_emb1: 8
input_emb2: 13
d_model: 128
d_k: 128
actor_mlp_hidden_layers: [128, 64, 6]
critic_mlp_hidden_layers: [128, 64, 1]
num_episodes: 50_000  # number of episodes to train
gamma: 0.99  # discount factor
lr: 0.0001  # learning rate
entropy_penalty: 0.001 # entropy penalty
save_path: "./models/a2c_transformer"  # path to save the model files
render: False  # setting it to True would render after every "render_freq" episodes
render_freq: 500  # if render is True, the episode will be rendered after every render_freq episodes
save_freq: 50  # model would be saved after every save_freq epsidoes
